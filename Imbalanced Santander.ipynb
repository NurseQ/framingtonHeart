{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80f0807e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# this classifier usually outperforms most off the shelf classifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# metric for optimization\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# some methods we need to work with imbalanced data are sensitive to the magnitude of features\n",
    "# such as KNN\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# reduce no. of features\n",
    "from feature_engine.selection import (DropDuplicateFeatures,\n",
    "                                     DropConstantFeatures)\n",
    "\n",
    "# over sampling\n",
    "from imblearn.over_sampling import (RandomOverSampler, SMOTENC)\n",
    "\n",
    "# under sampling\n",
    "\n",
    "from imblearn.under_sampling import (InstanceHardnessThreshold,\n",
    "                                    RandomUnderSampler)\n",
    "\n",
    "# ensemble methods with boosting which tend to work better\n",
    "\n",
    "from imblearn.ensemble import (RUSBoostClassifier,\n",
    "                              EasyEnsembleClassifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6660049b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Santander Customer Satisfaction dataset\n",
    "data = pd.read_csv(\"..\\\\train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7f54a8",
   "metadata": {},
   "source": [
    "### Variable Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16a1d52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "nullCol=[]\n",
    "\n",
    "for i in data.columns:\n",
    "    if data[i].isnull().sum()>0:\n",
    "        append.nullCol\n",
    "\n",
    "print(nullCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aefeedca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#put in a list any column with strings\n",
    "list(data.select_dtypes(include='object').columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "877edd77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140 variables with less than or equal to 2 values\n",
      "239 variables with less than or equal to 10 values\n",
      "254 variables with less than or equal to 20 values\n"
     ]
    }
   ],
   "source": [
    "# check the dataset if how many are binary of have <10 or <20 unique variables\n",
    "\n",
    "for unique in [2,10,20]:\n",
    "    vars_ = [x for x in data.columns if data[x].nunique()<=unique]\n",
    "    vars_ = len(vars_)\n",
    "    print(f'{vars_} variables with less than or equal to {unique} values')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38459a3",
   "metadata": {},
   "source": [
    "This shows that we have 140 features that are binary. This is important for over sampling or under sampling methods for imbalanced datasets as some methods use distance metrics that are not suitable for discrete variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecbceed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15204, 369), (60816, 369))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(['ID', 'TARGET'],axis=1), data['TARGET'], test_size=0.8,) # test_size increased to prevent loss of memory \n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7461463c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    0.961063\n",
       " 1    0.038937\n",
       " Name: TARGET, dtype: float64,\n",
       " 0    14612\n",
       " 1      592\n",
       " Name: TARGET, dtype: int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the imbalance, 0 is satisfied, 1 is not satisfied\n",
    "\n",
    "y_train.value_counts(normalize=True), y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b662072a",
   "metadata": {},
   "source": [
    "### Drop constant, quasi-constant and duplicated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70931419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('constant', DropConstantFeatures()),\n",
       "                ('duplicated', DropDuplicateFeatures())])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([('constant', DropConstantFeatures(tol=1)),\n",
    "                ('duplicated',DropDuplicateFeatures())])\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8acecf88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see how many constant features in the dataset\n",
    "len(pipe.named_steps['constant'].features_to_drop_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6778b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see number of duplicated features are in the dataset\n",
    "len(pipe.named_steps['duplicated'].features_to_drop_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9493b78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of features before drop:  369\n",
      "No. of features after drop:  266\n"
     ]
    }
   ],
   "source": [
    "# go ahead and remove all duplicated and constant features\n",
    "print('No. of features before drop: ', X_train.shape[1])\n",
    "\n",
    "X_train = pipe.transform(X_train)\n",
    "X_test = pipe.transform(X_test)\n",
    "\n",
    "print('No. of features after drop: ', X_train.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cac53b4",
   "metadata": {},
   "source": [
    "### Gradient Boosting\n",
    "\n",
    "Gradient boosting models outperform all off the shelf classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2853eb07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(loss='exponential', max_depth=1,\n",
       "                           min_samples_split=0.8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm = GradientBoostingClassifier(loss='exponential',\n",
    "                                 max_depth=1,\n",
    "                                 min_samples_split= 0.80,\n",
    "                                 n_estimators=100)\n",
    "\n",
    "gbm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "212ed4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train roc_auc score 0.8383042954328541\n",
      "Test roc_auc score 0.8224287143926335\n"
     ]
    }
   ],
   "source": [
    "# benchmark scores\n",
    "\n",
    "X_train_pred = gbm.predict_proba(X_train)[:,1]\n",
    "X_test_pred = gbm.predict_proba(X_test)[:,1]\n",
    "\n",
    "print('Train roc_auc score', roc_auc_score(y_train, X_train_pred))\n",
    "print('Test roc_auc score', roc_auc_score(y_test, X_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34eebaa0",
   "metadata": {},
   "source": [
    "## Handling Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a41ef2d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15204, 266), (1359, 266))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using Instance Hardness Threshold to remove difficult to classify observations correctly from the majority class\n",
    "# A measure of how difficult to clasify an observation correctly, it is inversely correlated to the probability of its class.\n",
    "\n",
    "iht = InstanceHardnessThreshold(estimator=gbm, # gradient boosting classifier\n",
    "                               sampling_strategy='auto',# undersamples only the majority class\n",
    "                               cv=2) \n",
    "\n",
    "# resample\n",
    "X_resampled, y_resampled = iht.fit_resample(X_train, y_train)\n",
    "\n",
    "# shape of original data and resampled data\n",
    "X_train.shape, X_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfcd9e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.564386\n",
       "1    0.435614\n",
       "Name: TARGET, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see resampled ratio, instance hardness is a fixed method and aims for 50:50\n",
    "y_resampled.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d79678c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(loss='exponential', max_depth=1,\n",
       "                           min_samples_split=0.8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model on the resampled data\n",
    "\n",
    "gbm.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c0e5f09",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train roc_auc score 0.999514385637267\n",
      "Test roc_auc score 0.8085084950217727\n"
     ]
    }
   ],
   "source": [
    "X_train_pred = gbm.predict_proba(X_resampled)[:,1]\n",
    "X_test_pred = gbm.predict_proba(X_test)[:,1]\n",
    "\n",
    "print('Train roc_auc score', roc_auc_score(y_resampled, X_train_pred))\n",
    "print('Test roc_auc score', roc_auc_score(y_test, X_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877a0918",
   "metadata": {},
   "source": [
    "The model overfits the train set and the test set also does not show better performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8ed624",
   "metadata": {},
   "source": [
    "### Random UnderSampling\n",
    "Quite often neglected as it reduces the training set significantly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71c0762c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15204, 266), (1184, 266))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rus = RandomUnderSampler(\n",
    "        sampling_strategy='auto',) #undersamples only the majority class\n",
    "\n",
    "X_resampled, y_resampled=rus.fit_resample(X_train,y_train)\n",
    "\n",
    "X_train.shape, X_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76c6b087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    0.5\n",
       " 1    0.5\n",
       " Name: TARGET, dtype: float64,\n",
       " 0    592\n",
       " 1    592\n",
       " Name: TARGET, dtype: int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_resampled.value_counts(normalize=True), y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6affa9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(loss='exponential', max_depth=1,\n",
       "                           min_samples_split=0.8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "gbm.fit(X_resampled,y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "515454ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train roc_auc:  0.8403573548210372\n",
      "Test roc)_auc:  0.8234451154687926\n"
     ]
    }
   ],
   "source": [
    "# Get the performance of the train and test set\n",
    "\n",
    "X_train_pred = gbm.predict_proba(X_resampled)[:,1]\n",
    "X_test_pred = gbm.predict_proba(X_test)[:,1]\n",
    "\n",
    "print('Train roc_auc: ', roc_auc_score(y_resampled, X_train_pred))\n",
    "print('Test roc)_auc: ', roc_auc_score(y_test, X_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1a98d9",
   "metadata": {},
   "source": [
    "Even with undersampling, the result still doesn't show any marked improvement compared to using all the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1af4f7",
   "metadata": {},
   "source": [
    "### Random Oversampling\n",
    "In essence duplicates data in the minority class, so may lead to over fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb7fb865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15204, 266), (29224, 266))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ros=RandomOverSampler(sampling_strategy='auto')\n",
    "\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "X_train.shape, X_resampled.shape # we have more samples now in the minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b8779c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.5\n",
       "1    0.5\n",
       "Name: TARGET, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_resampled.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2eccf20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(loss='exponential', max_depth=1,\n",
       "                           min_samples_split=0.8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model on the resampled data\n",
    "gbm.fit(X_resampled,y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "940de0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train roc_auc:  0.8422503808523855\n",
      "Test roc_auc:  0.8269924107547855\n"
     ]
    }
   ],
   "source": [
    "# see performance of the model on the train and test set\n",
    "X_train_pred = gbm.predict_proba(X_resampled)[:,1]\n",
    "X_test_pred = gbm.predict_proba(X_test)[:,1]\n",
    "\n",
    "print('Train roc_auc: ', roc_auc_score(y_resampled, X_train_pred))\n",
    "print('Test roc_auc: ', roc_auc_score(y_test, X_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70408cf",
   "metadata": {},
   "source": [
    "Still, the model offers a small increase in performance. We would have to use cross-validation and get a measure of the error dispersion to be sure to see if it is within the error of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1272e3",
   "metadata": {},
   "source": [
    "## SMOTENC\n",
    "Smote interpolate synthetic data using its 5 nearest neighbors, SMOTE-NC will be used as it works with discrete data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1246a6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we need to find out the index of features that are categorical of discrete\n",
    "\n",
    "# capture discrete features in a list\n",
    "cat_feats = [feat for feat in X_train.columns if X_train[feat].nunique()<=10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6b884332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# capture the index in the dataframe columns\n",
    "cat_feats_index = [cat_feats.index(x) for x in cat_feats]\n",
    "\n",
    "cat_feats_index[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff36ffa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15204, 266), (29224, 266))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smnc = SMOTENC(\n",
    "    sampling_strategy='auto', # samples only the minority class\n",
    "    random_state=0,  # for reproducibility\n",
    "    k_neighbors=3,\n",
    "    categorical_features=cat_feats_index # indeces of the columns of discrete variables\n",
    ")  \n",
    "\n",
    "# because SMOTE uses KNN, and KNN is sensible to variable magnitude, we re-scale the data\n",
    "\n",
    "# this procedure will take a while, it also caused memory problems so train/test ratio was increased for test\n",
    "X_resampled, y_resampled = smnc.fit_resample(MinMaxScaler().fit_transform(X_train), y_train)\n",
    "\n",
    "X_train.shape, X_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eee0118b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.5\n",
       "1    0.5\n",
       "Name: TARGET, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the distribution of the resampled target\n",
    "# we should have 50:50 now\n",
    "\n",
    "y_resampled.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "35a929c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(loss='exponential', max_depth=1,\n",
       "                           min_samples_split=0.8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model \n",
    "\n",
    "gbm.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d2d4e928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train roc_auc:  0.8646859426296062\n",
      "Test roc_auc:  0.7009333573834255\n"
     ]
    }
   ],
   "source": [
    "# Now let's get the performance on train and test\n",
    "\n",
    "X_train_preds = gbm.predict_proba(X_resampled)[:,1]\n",
    "X_test_preds = gbm.predict_proba(X_test)[:,1]\n",
    "\n",
    "print('Train roc_auc: ', roc_auc_score(y_resampled, X_train_preds))\n",
    "print('Test roc_auc: ', roc_auc_score(y_test, X_test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833e9651",
   "metadata": {},
   "source": [
    "SMOTENC oversampling method is worse for the outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaf40cc",
   "metadata": {},
   "source": [
    "### Ensemble Methods\n",
    "\n",
    "RUSBoost and Easy Ensemble, both based on boosting methods tend to return better performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c1d8e3bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15204, 369), (60816, 369))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load Santander Customer Satisfaction dataset\n",
    "data = pd.read_csv(\"..\\\\train.csv\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(['ID', 'TARGET'],axis=1), data['TARGET'], test_size=0.8,) # test size returned to usual size\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e17c054c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RUSBoostClassifier(n_estimators=20, random_state=2909)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set up the RUSBoost ensemble model\n",
    "\n",
    "rusboost = RUSBoostClassifier(\n",
    "        base_estimator=None,\n",
    "        n_estimators=20,\n",
    "        learning_rate=1.0,\n",
    "        sampling_strategy='auto',\n",
    "        random_state=2909,\n",
    "    )\n",
    "\n",
    "\n",
    "# train model\n",
    "rusboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e2366eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train roc_auc:  0.7917998230453688\n",
      "Test roc_auc:  0.7670432185064462\n"
     ]
    }
   ],
   "source": [
    "# Now let's get the performance on train and test\n",
    "\n",
    "X_train_preds = rusboost.predict_proba(X_train)[:,1]\n",
    "X_test_preds = rusboost.predict_proba(X_test)[:,1]\n",
    "\n",
    "print('Train roc_auc: ', roc_auc_score(y_train, X_train_preds))\n",
    "print('Test roc_auc: ', roc_auc_score(y_test, X_test_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "95a7a4d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EasyEnsembleClassifier(random_state=2909)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "easy = EasyEnsembleClassifier(\n",
    "        n_estimators=10,\n",
    "        sampling_strategy='auto',\n",
    "        random_state=2909,\n",
    "    )\n",
    "\n",
    "\n",
    "# train model\n",
    "easy.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c0eee095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train roc_auc:  0.8585754787303099\n",
      "Test roc_auc:  0.8013171721426242\n"
     ]
    }
   ],
   "source": [
    "# Now let's get the performance on train and test\n",
    "\n",
    "X_train_preds = easy.predict_proba(X_train)[:,1]\n",
    "X_test_preds = easy.predict_proba(X_test)[:,1]\n",
    "\n",
    "print('Train roc_auc: ', roc_auc_score(y_train, X_train_preds))\n",
    "print('Test roc_auc: ', roc_auc_score(y_test, X_test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044d2515",
   "metadata": {},
   "source": [
    "Ensemble methods did not improve the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472dd049",
   "metadata": {},
   "source": [
    "### Cost sensitive approach\n",
    "Misclassification of the minority class will be penalized at a higher cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "55813ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(loss='exponential', max_depth=1,\n",
       "                           min_samples_split=0.8)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we have an imbalance of 95 to 5, so we use those as weights\n",
    "sample_weight = np.where(y_train==1, 95, 5)\n",
    "\n",
    "# train model\n",
    "gbm.fit(X_train, y_train, sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6ede09fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train roc_auc:  0.8435694105541656\n",
      "Test roc_auc:  0.8252720943968265\n"
     ]
    }
   ],
   "source": [
    "# Now let's get the performance on train and test\n",
    "\n",
    "X_train_preds = gbm.predict_proba(X_train)[:,1]\n",
    "X_test_preds = gbm.predict_proba(X_test)[:,1]\n",
    "\n",
    "print('Train roc_auc: ', roc_auc_score(y_train, X_train_preds))\n",
    "print('Test roc_auc: ', roc_auc_score(y_test, X_test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec05a32",
   "metadata": {},
   "source": [
    "From all the techniques that we tested in this notebook, the benchmark model trained on the entire dataset and the 1 with cost-sensitive learning seem to be the ones that perform the best. So to follow up, we could optimize parameters on these to see if this improves model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3abb912",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1579b9ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4cc2d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72847917",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
